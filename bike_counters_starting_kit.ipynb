{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RAMP on predicting cyclist traffic in Paris\n",
    "\n",
    "Authors: *Roman Yurchak (Symerio)*; also partially inspired by the air_passengers starting kit.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The dataset was collected with cyclist counters installed by Paris city council in multiple locations. It contains hourly information about cyclist traffic, as well as the following features,\n",
    " - counter name\n",
    " - counter site name\n",
    " - date\n",
    " - counter installation date\n",
    " - latitude and longitude\n",
    " \n",
    "Available features are quite scarce. However, **we can also use any external data that can help us to predict the target variable.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Loading the data with pandas\n",
    "\n",
    "First, download the data files with the `download_data` script:\n",
    "```bash\n",
    "!conda activate bikes-ramp\n",
    "!python download_data.py\n",
    "```\n",
    "It will untar the archive and put the train and test file in the data folder.\n",
    "\n",
    "\n",
    "Data is stored in [Parquet format](https://parquet.apache.org/), an efficient columnar data format. We can load the train set with pandas,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(Path(\"data\") / \"train.parquet\").sort_values(by=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "We can check general information about different columns,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "and in particular the number of unique entries in each column,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We have a 30 counting sites where sometimes multiple counters are installed per location.  Let's look at the most frequented stations,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby([\"site_name\", \"counter_name\"], observed=True)[\"bike_count\"].sum().sort_values(\n",
    "    ascending=False\n",
    ").head(10).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Visualizing the data\n",
    "\n",
    "\n",
    "Let's visualize the data, starting from the spatial distribution of counters on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map(location=data[[\"latitude\", \"longitude\"]].mean(axis=0), zoom_start=13)\n",
    "\n",
    "for _, row in (\n",
    "    data[[\"counter_name\", \"latitude\", \"longitude\"]]\n",
    "    .drop_duplicates(\"counter_name\")\n",
    "    .iterrows()\n",
    "):\n",
    "    folium.Marker(\n",
    "        row[[\"latitude\", \"longitude\"]].values.tolist(), popup=row[\"counter_name\"]\n",
    "    ).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Note that in this RAMP problem we consider only the 30 most frequented counting sites, to limit data size.\n",
    "\n",
    "\n",
    "Next, we will look into the temporal distribution of the most frequented bike counter. If we plot it directly we will not see much because there are half a million data points,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data[\"counter_name\"] == \"Totem 73 boulevard de Sébastopol S-N\"\n",
    "\n",
    "data[mask].plot(x=\"date\", y=\"bike_count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Instead we aggregate the data, for instance, by week to have a clearer overall picture,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data[\"counter_name\"] == \"Totem 73 boulevard de Sébastopol S-N\"\n",
    "\n",
    "data[mask].groupby(pd.Grouper(freq=\"1W\", key=\"date\"))[[\"bike_count\"]].sum().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "While at the same time, we can zoom on a week in particular for a more short-term visualization,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "mask = (\n",
    "    (data[\"counter_name\"] == \"Totem 73 boulevard de Sébastopol S-N\")\n",
    "    & (data[\"date\"] > pd.to_datetime(\"2021/03/01\"))\n",
    "    & (data[\"date\"] < pd.to_datetime(\"2021/03/08\"))\n",
    ")\n",
    "\n",
    "data[mask].plot(x=\"date\", y=\"bike_count\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "The hourly pattern has a clear variation between work days and weekends (7 and 8 March 2021).\n",
    "\n",
    "If we look at the distribution of the target variable it skewed and non normal, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.histplot(data, x=\"bike_count\", kde=True, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Least square loss would not be appropriate to model it since it is designed for normal error distributions. One way to precede would be to transform the variable with a logarithmic transformation,\n",
    "```py\n",
    "data['log_bike_count'] = np.log(1 + data['bike_count'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(data, x=\"log_bike_count\", kde=True, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "which has a more pronounced central mode, but is still non symmetric. In the following, **we use `log_bike_count` as the target variable** as otherwise `bike_count` ranges over 3 orders of magnitude and least square loss would be dominated by the few large values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "To account for the temporal aspects of the data, we cannot input the `date` field directly into the model. Instead we extract the features on different time-scales from the `date` field, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_dates(X):\n",
    "    X = X.copy()  # modify a copy of X\n",
    "    # Encode the date information from the DateOfDeparture columns\n",
    "    X.loc[:, \"year\"] = X[\"date\"].dt.year\n",
    "    X.loc[:, \"month\"] = X[\"date\"].dt.month\n",
    "    X.loc[:, \"day\"] = X[\"date\"].dt.day\n",
    "    X.loc[:, \"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X.loc[:, \"hour\"] = X[\"date\"].dt.hour\n",
    "\n",
    "    # Finally we can drop the original columns from the dataframe\n",
    "    return X.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "_encode_dates(data[[\"date\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "To use this function with scikit-learn estimators we wrap it with [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates, validate=False)\n",
    "date_encoder.fit_transform(data[[\"date\"]]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Since it is unlikely that, for instance, that `hour` is linearly correlated with the target variable, we would need to additionally encode categorical features for linear models. This is classically done with [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), though other encoding strategies exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "enc.fit_transform(_encode_dates(data[[\"date\"]])[[\"hour\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Let's now construct our first linear model with [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). We use a few helper functions defined in `problem.py` of the starting kit to load the public train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem\n",
    "\n",
    "X_train, y_train = problem.get_train_data()\n",
    "X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Where `y` contains the `log_bike_count` variable. \n",
    "\n",
    "The test set is in the future as compared to the train set,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'Train: n_samples={X_train.shape[0]},  {X_train[\"date\"].min()} to {X_train[\"date\"].max()}'\n",
    ")\n",
    "print(\n",
    "    f'Test: n_samples={X_test.shape[0]},  {X_test[\"date\"].min()} to {X_test[\"date\"].max()}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "_encode_dates(X_train[[\"date\"]]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)\n",
    "date_cols = _encode_dates(X_train[[\"date\"]]).columns.tolist()\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "categorical_cols = [\"counter_name\", \"site_name\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"date\", OneHotEncoder(handle_unknown=\"ignore\"), date_cols),\n",
    "        (\"cat\", categorical_encoder, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "regressor = Ridge()\n",
    "\n",
    "pipe = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "We then evaluate this model with the RMSE metric,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "print(\n",
    "    f\"Train set, RMSE={root_mean_squared_error(y_train, pipe.predict(X_train)):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test set, RMSE={root_mean_squared_error(y_test, pipe.predict(X_test)):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "The model doesn't have enough capacity to generalize on the train set, since we have lots of data with relatively few parameters. However it happened to work somewhat better on the test set. We can compare these results with the baseline predicting the mean value,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline mean prediction.\")\n",
    "print(\n",
    "    f\"Train set, RMSE={root_mean_squared_error(y_train, np.full(y_train.shape, y_train.mean())):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test set, RMSE={root_mean_squared_error(y_test, np.full(y_test.shape, y_test.mean())):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "which illustrates that we are performing better than the baseline.\n",
    "\n",
    "Let's visualize the predictions for one of the stations,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (\n",
    "    (X_test[\"counter_name\"] == \"Totem 73 boulevard de Sébastopol S-N\")\n",
    "    & (X_test[\"date\"] > pd.to_datetime(\"2021/09/01\"))\n",
    "    & (X_test[\"date\"] < pd.to_datetime(\"2021/09/08\"))\n",
    ")\n",
    "\n",
    "df_viz = X_test.loc[mask].copy()\n",
    "df_viz[\"bike_count\"] = np.exp(y_test[mask.values]) - 1\n",
    "df_viz[\"bike_count (predicted)\"] = np.exp(pipe.predict(X_test[mask])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "df_viz.plot(x=\"date\", y=\"bike_count\", ax=ax)\n",
    "df_viz.plot(x=\"date\", y=\"bike_count (predicted)\", ax=ax, ls=\"--\")\n",
    "ax.set_title(\"Predictions with Ridge\")\n",
    "ax.set_ylabel(\"bike_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "So we start to see the daily trend, and some of the week day differences are accounted for, however we still miss the details and the spikes in the evening are under-estimated.\n",
    "\n",
    "A useful way to visualize the error is to plot the prediction error using `PredictionErrorDisplay`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a797cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "\n",
    "df_viz = pd.DataFrame({\"y_true\": y_test, \"y_pred\": pipe.predict(X_test)}).sample(\n",
    "    1_000, random_state=0\n",
    ")\n",
    "y_pred = pipe.predict(X_test)\n",
    "display = PredictionErrorDisplay(y_true=df_viz[\"y_true\"], y_pred=df_viz[\"y_pred\"])\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "It is recommended to use cross-validation for hyper-parameter tuning with [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) or more reliable model evaluation with [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score). In this case, because we want the test data to always be in the future as compared to the train data, we can use [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html),\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/Q37Bn.png\" />\n",
    "\n",
    "The disadvantage, is that we can either have the training set size be different for each fold which is not ideal for hyper-parameter tuning (current figure), or have constant sized small training set which is also not ideal given the data periodicity. This explains that generally we will have worse cross-validation scores than test scores, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=6)\n",
    "\n",
    "# When using a scorer in scikit-learn it always needs to be better when smaller, hence the minus sign.\n",
    "scores = cross_val_score(\n",
    "    pipe, X_train, y_train, cv=cv, scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "print(\"RMSE: \", scores)\n",
    "print(f\"RMSE (all folds): {-scores.mean():.3} ± {(-scores).std():.3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikes-ramp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
